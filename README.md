
# Awesome-Social-Agent [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

### üî•üî•üî• AGIÁ©∫Èó¥(https://agispace.feishu.cn/wiki/JkVuwRaXniSDShklwhMc1b2bnId)


## üì¢ News
[04/20/2025]

üì¢ 

‚ú® 

üöÄ **What's New in This Update**:
<br>‚úÖ Updated to include around 100 additional Vid-LLMs and 15 new benchmarks as of June 2024.

Multiple minor updates will follow this major update. And the GitHub repository will be gradually updated soon. We welcome your reading and feedback ‚ù§Ô∏è

<font size=5><center><b> Table of Contents </b> </center></font>
- [Awesome-LLMs-for-Video-Understanding ](#awesome-llms-for-video-understanding-)
    - [üî•üî•üî• Video Understanding with Large Language Models: A Survey](#-video-understanding-with-large-language-models-a-survey)
  - [Why we need Vid-LLMs?](#why-we-need-vid-llms)
  - [‚ú® Survey](#-survey)
  - [üòé Vid-LLMs: Models](#-vid-llms-models)
    - [üìë Citation](#-citation)
      - [üóíÔ∏è Taxonomy 1](#Ô∏è-taxonomy-1)
        - [üïπÔ∏è Video Analyzer √ó LLM](#Ô∏è-video-analyzer--llm)
          - [LMM as Summarizer](#lmm-as-summarizer)
          - [LLM as Manager](#llm-as-manager)
        - [üëæ Video Embedder √ó LLM](#-analyzer--embedder--llm)
          - [LLM as Text Decoder](#llm-as-text-decoder)
          - [LLM as Regressor](#llm-as-regressor)
          - [LLM as Hidden Layer](#llm-as-hidden-layer)
        - [üß≠ (Analyzer + Embedder) √ó LLM](#-analyzer--embedder--llm)
          - [LLM as Manager](#llm-as-manager-1)
          - [LMM as Summarizer](#lmm-as-summarizer-1)
          - [LLM as Text Decoder](#llm-as-text-decoder-1)
          - [LLM as Regressor](#llm-as-regressor-1)
          - [LLM as Hidden Layer](#llm-as-hidden-layer-1)
      - [üóíÔ∏è Taxonomy 2](#Ô∏è-taxonomy-2)
        - [ü§ñ LLM-based Video Agents](#-llm-based-video-agents)
        - [üé• Vid-LLM Pretraining](#-vid-llm-pretraining)
        - [üëÄ Vid-LLM Instruction Tuning](#-vid-llm-instruction-tuning)
          - [Fine-tuning with Connective Adapters](#fine-tuning-with-connective-adapters)
          - [Fine-tuning with Insertive Adapters](#fine-tuning-with-insertive-adapters)
          - [Fine-tuning with Hybrid Adapters](#fine-tuning-with-hybrid-adapters)
        - [ü¶æ Hybrid Methods](#-hybrid-methods)
        - [Training-free Methods](#-training-free-methods)
  - [Tasks, Datasets, and Benchmarks](#tasks-datasets-and-benchmarks)
      - [Recognition and Anticipation](#recognition-and-anticipation)
      - [Captioning and Description](#captioning-and-description)
      - [Grounding and Retrieval](#grounding-and-retrieval)
      - [Question Answering](#question-answering)
      - [Video Instruction Tuning](#video-instruction-tuning)
        - [Pretraining Dataset](#pretraining-dataset)
        - [Fine-tuning Dataset](#fine-tuning-dataset)
      - [Video-based Large Language Models Benchmark](#video-based-large-language-models-benchmark)
  - [Contributing](#contributing)
    - [üåü Star History](#-star-history)
    - [‚ô•Ô∏è Contributors](#Ô∏è-contributors)

## Why we need Vid-LLMs?

![image](./img/tasks.png)

## ‚ú® Survey
| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |
| [**Agent AI: Surveying the Horizons of Multimodal Interaction**](https://arxiv.org/abs/2401.03568) |   Agent AI   | 01/2024 |      [code]()       | arXiv |


## üòé Vid-LLMs: Models 

![image](./img/timeline.png)

### üìë Citation

### üóíÔ∏è Taxonomy 1

#### üïπÔ∏è Video Analyzer √ó LLM

##### LLM as Summarizer
| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |



##### LLM as Manager
| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |



#### üëæ Video Embedder √ó LLM

##### LLM as Text Decoder

| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |



##### LLM as Regressor

| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |



##### LLM as Hidden Layer
 | Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |



#### üß≠ (Analyzer + Embedder) √ó LLM

##### LLM as Manager
 | Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |

##### LLM as Summarizer
 | Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |

##### LLM as Regressor
 | Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |


##### LLM as Text Decoder
 | Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |


##### LLM as Hidden Layer
 | Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |

### üóíÔ∏è Taxonomy 2

#### ü§ñ LLM-based Video Agents

| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |




#### üé• Vid-LLM Pretraining

| Title                                                        |  Model  |  Date   |                        Code                        |  Venue  |
| :----------------------------------------------------------- | :-----: | :-----: | :------------------------------------------------: | :-----: |
| [**Learning Video Representations from Large Language Models**](https://arxiv.org/abs/2212.04501)[![Star](https://img.shields.io/github/stars/facebookresearch/lavila?style=social&label=Star)](https://github.com/facebookresearch/lavila) | LaViLa  | 12/2022 | [code](https://github.com/facebookresearch/lavila) |  CVPR   |


#### üëÄ Vid-LLM Instruction Tuning

##### Fine-tuning with Connective Adapters

| Title                                                        |     Model     |  Date   |                         Code                         | Venue |
| :----------------------------------------------------------- | :-----------: | :-----: | :--------------------------------------------------: | :---: |
| [**Video-LLaMA: An Instruction-Finetuned Visual Language Model for Video Understanding**](https://arxiv.org/abs/2306.02858) [![Star](https://img.shields.io/github/stars/DAMO-NLP-SG/Video-LLaMA.svg?style=social&label=Star)](https://github.com/DAMO-NLP-SG/Video-LLaMA) |  Video-LLaMA  | 06/2023 |  [code](https://github.com/DAMO-NLP-SG/Video-LLaMA)  | arXiv |


##### Fine-tuning with Insertive Adapters

| Title                                                        |  Model   |  Date   |                    Code                    | Venue |
| :----------------------------------------------------------- | :------: | :-----: | :----------------------------------------: | :---: |


##### Fine-tuning with Hybrid Adapters

| Title                                                        |   Model   |  Date   |                     Code                     | Venue |
| :----------------------------------------------------------- | :-------: | :-----: | :------------------------------------------: | :---: |


#### ü¶æ Hybrid Methods

| Title                                                        |        Model        |  Date   |                             Code                             | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :----------------------------------------------------------: | :---: |
    

#### üíé Training-free Methods

| Title                                                        |        Model        |  Date   | Code | Venue |
| :----------------------------------------------------------- | :-----------------: | :-----: | :--: | :---: |



---

## Tasks, Datasets, and Benchmarks

#### Recognition and Anticipation

| Name               |                            Paper                             | Date |                            Link                             |  Venue  |
| :----------------- | :----------------------------------------------------------: | :--: | :---------------------------------------------------------: | :-----: |



#### Captioning and Description
| Name               |                            Paper                             | Date |                            Link                             |  Venue  |
| :----------------- | :----------------------------------------------------------: | :--: | :---------------------------------------------------------: | :-----: |



#### Grounding and Retrieval
| Name               |                            Paper                             | Date |                            Link                             |  Venue  |
| :----------------- | :----------------------------------------------------------: | :--: | :---------------------------------------------------------: | :-----: |



#### Question Answering
| Name               |                            Paper                             | Date |                            Link                             |  Venue  |
| :----------------- | :----------------------------------------------------------: | :--: | :---------------------------------------------------------: | :-----: |


#### Video Instruction Tuning
##### Pretraining Dataset
| Name               |                            Paper                             | Date |                            Link                             |  Venue  |
| :----------------- | :----------------------------------------------------------: | :--: | :---------------------------------------------------------: | :-----: |



##### Fine-tuning Dataset
| Name               |                            Paper                             | Date |                            Link                             |  Venue  |
| :----------------- | :----------------------------------------------------------: | :--: | :---------------------------------------------------------: | :-----: |



#### Video-based Large Language Models Benchmark

| Title                                                        |  Date   |                            Code                            |              Venue               |
| :----------------------------------------------------------- | :-----: | :--------------------------------------------------------: | :------------------------------: |




## Contributing

We welcome everyone to contribute to this repository and help improve it. You can submit pull requests to add new papers, projects, and helpful materials, or to correct any errors that you may find. Please make sure that your pull requests follow the "Title|Model|Date|Code|Venue" format. Thank you for your valuable contributions!


### üåü Star History

[![Star History Chart](https://api.star-history.com/svg?repos=yunlong10/Awesome-LLMs-for-Video-Understanding&type=Date)](https://star-history.com/#yunlong10/Awesome-LLMs-for-Video-Understanding&Date)

### ‚ô•Ô∏è Contributors

Our project wouldn't be possible without the contributions of these amazing people! Thank you all for making this project better.

[Feng Kai](https://github.com/fengkaifengkai/18704466567.github.io) @ University of WhuHan \



<a href="https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding/graphs/contributors">
  <img src="https://github.com/fengkaifengkai/AgentSocial" />
</a>

